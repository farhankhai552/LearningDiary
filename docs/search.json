[
  {
    "objectID": "wk1.html",
    "href": "wk1.html",
    "title": "Remote Sensing Learning Diary",
    "section": "",
    "text": "Remote sensing is the process of acquiring information (mainly geographic imagery of Earth features) from a distance (also known as Earth Observation).\nThis is achieved through sensors mounted on a platform, which reflect energy (containing information) to the ground station\nPlatforms containing sensors include: planes, drones, satellites, and phones\nEnergy reflected from sensors to ground station is known as electromagnetic waves.\n\nHow does it work?\n\nEnergy reflected from energy source (sun) to sensors to ground station is known as electromagnetic radiation\n\nEMR energy does not automatically reflect to sensor, goes through changes via surface and atmosphere first\n\nMain example of remote sensing is satellites circling the earth containing sensors which reflect available energy (mainly from the sun). This is known as passive remote sensing.\nActive remote sensing is when sensors contain their own energy source for illumination. Examples include x-rays and radars.\n\nWhat are its applications?\n\n\n\n\n\n\n\nCol1\nCol2\n\n\n\n\nDynamic world (sentinel data)\nNear real-time cover dataset (10m resolution)\n\n\nLandsat\nUrban/green space coverage and accessibility\n\n\nSentinel\nPollution studies\n\n\nLandsat and sentinel\nIllegal logging\n\n\nLandsat\nForest fires\n\n\nLandsat and sentinel\nTemperature studies (e.g. urban heat island)\n\n\nLandsat, sentinel, and SAR\nFlooding/disaster response/building footprints\n\n\n\n\n\n\n\nConsiderations when dealing with remotely sensed data\n\nAtmospheric interference (scattering due to weather, etc)\nResolution type and detail\n\nMain concepts\n\nElectromagnetic radiation (EMR) = electric + magnetic fields moving as waves (found in all forms of waves)\nRadiant energy = energy carried by EMR waves\nShortwave radiation = energy from the sun\nRAYLEIGH SCATTERING = Scattering of atmospheric particles\nRESOLUTION = potential detail provided by imagery\n\nSpatial = size of raster grid\nSpectral = capacity of a sensor to document electromagnetic wavelengths/number of bands from EM spectrum (which could include colour, infrared light, and more). In other words, describes the ability of a sensor to define fine wavelength intervals\n\nThe finer the spectral resolution, the narrower the range that a sensor can document. Often earth surfaces require multispectral data for it to form a true colour image.\n\nTemporal = time a location is revisited\nRadiometric = ability to discriminate slight differences in energy\n\n\nPersonal reflection\n\nIntroduced to the concept of remote sensing (how it works, applications in a modern setting, how it can be utilised to track global phenomena).\nThere are always considerations when working with data depending on factors such as resolution type, atmospheric determinants which lead to distortion, other types of interference (all of which can be corrected to a certain extent).\nAllowed me to consider a new angle to approaching data-driven solutions regarding environmental issues, from solving urban heat temperature issues due to the placement of built features, to disaster risk management.\nHome country of Malaysia suffers from many environmental and man-made hazards.\nAs someone from Southeast Asia, a region becoming increasingly prone to climate risks, the potential to provide solutions using this kind of data may help decrease and/or eliminate the collateral damage caused by natural disasters, as well as pinpoint root causes in order to form data-backed solutions."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Remote Sensing Learning Diary",
    "section": "",
    "text": "Purpose\nThis learning diary acts as an assignment for the module CASA00023 Remote Sensing Cities and Environment. Each week covers a different topic pertaining to remote sensing.\nThis book is created from R markdown and executable code."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1: Intro to Remote Sensing",
    "section": "",
    "text": "Remote sensing is the process of acquiring information (mainly geographic imagery of Earth features) from a distance (also known as Earth Observation).\nThis is achieved through sensors mounted on a platform, which reflect energy (containing information) to the ground station\nPlatforms containing sensors include: planes, drones, satellites, and phones\nEnergy reflected from sensors to ground station is known as electromagnetic waves.\n\nHow does it work?\n\nEnergy reflected from energy source (sun) to sensors to ground station is known as electromagnetic radiation\n\nEMR energy does not automatically reflect to sensor, goes through changes via surface and atmosphere first\n\nMain example of remote sensing is satellites circling the earth containing sensors which reflect available energy (mainly from the sun). This is known as passive remote sensing.\nActive remote sensing is when sensors contain their own energy source for illumination. Examples include x-rays and radars.\n\nWhat are its applications?\n\n\n\n\n\n\n\nSource\nApplications\n\n\n\n\nDynamic world (sentinel data)\nNear real-time cover dataset (10m resolution)\n\n\nLandsat\nUrban/green space coverage and accessibility\n\n\nSentinel\nPollution studies\n\n\nLandsat and sentinel\nIllegal logging\n\n\nLandsat\nForest fires\n\n\nLandsat and sentinel\nTemperature studies (e.g. urban heat island)\n\n\nLandsat, sentinel, and SAR\nFlooding/disaster response/building footprints\n\n\n\n\n\n\n\nConsiderations when dealing with remotely sensed data\n\nAtmospheric interference (scattering due to weather, etc)\nResolution type and detail\n\nMain concepts\n\nElectromagnetic radiation (EMR) = electric + magnetic fields moving as waves (found in all forms of waves)\nRadiant energy = energy carried by EMR waves\nShortwave radiation = energy from the sun\nRAYLEIGH SCATTERING = Scattering of atmospheric particles\nRESOLUTION = potential detail provided by imagery\n\nSpatial = size of raster grid\nSpectral = capacity of a sensor to document electromagnetic wavelengths/number of bands from EM spectrum (which could include colour, infrared light, and more). In other words, describes the ability of a sensor to define fine wavelength intervals\n\nThe finer the spectral resolution, the narrower the range that a sensor can document. Often earth surfaces require multispectral data for it to form a true colour image.\n\nTemporal = time a location is revisited\nRadiometric = ability to discriminate slight differences in energy\n\n\nPersonal reflection\n\nIntroduced to the concept of remote sensing (how it works, applications in a modern setting, how it can be utilised to track global phenomena).\nThere are always considerations when working with data depending on factors such as resolution type, atmospheric determinants which lead to distortion, other types of interference (all of which can be corrected to a certain extent).\nAllowed me to consider a new angle to approaching data-driven solutions regarding environmental issues, from solving urban heat temperature issues due to the placement of built features, to disaster risk management.\nHome country of Malaysia suffers from many environmental and man-made hazards.\nAs someone from Southeast Asia, a region becoming increasingly prone to climate risks, the potential to provide solutions using this kind of data may help decrease and/or eliminate the collateral damage caused by natural disasters, as well as pinpoint root causes in order to form data-backed solutions."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2: Image Correction and Data Joining",
    "section": "",
    "text": "MIT graduate, creator of Landsat and MultiSpectral System (MSS), pioneer of remote sensing.\n\nWhy image corrections are needed/ pre processing requirements\n\nNeeded when technical defects and deficiencies of the sensor and data transfer systems lead to mistakes in the image data construction.\nRaw remotely sensed image data are full of geometric and radiometric flaws caused by the curved shape of the Earth, the imperfectly transparent atmosphere, daily and seasonal variations in the amount of solar radiation received at the surface, and imperfections in scanning instruments, etc\n\n\n\nImagery correction types\n\nGeometric\n\nPurpose\n\nTo remove geometric distortion from a distorted image\nImage distortion can happen through rotation of Earth, wind from plane, uneven topography, off-nadir angle.\n\n\nSteps\n\nGround Control Points (GCP) for both image and map/reference coordinates are identified\nSensor model is built using GCP to give geometric transformation coefficients \n\nTransformation algorithms used to convert geometric (lat long) to geocentric (x,y) coordinates\n\nCoordinates are plotted to ensure line of best fit (minimal MSE) and variance for MSE (RMSE)\nResampling (used to calculate pixel values when one raster grid is fitted to another) to fix shift in data from sensor modeling\n\nTwo images (one correct/gold standard) overlap in order for pixels to line up\nAtmospheric\n\nPurpose\n\nTo remove scattering and absorption effects of the atmosphere on the reflectance values of images taken by satellite or airborne sensors\n2 main sources of environmental disturbance: atmos scattering & topographic attenuation (dimming and blurring effects)\n\nAtmos correction is only necessary for certain situations:\n\nSpectral signature (unique wavelength radiated by an object. Different objects have different signatures) through space and time\nBiophysical parameters (i.e. temperature, leaf area index, NDVI) are needed\nScattering leads to adjacency = radiance from nearby pixels is mixed into pixel of interest\nCorrection methods:\n\nRelative (when compared to others)\n\nSpectral band = A wavelength range in the spectrum of reflected or radiated electromagnetic (EM) energy to which a remote sensor is sensitive\nTo normalise intensities of different bands relative to each other within a single image\nTo normalise intensities of bands from many dates to one date\nRelative correction methods\n\nDark object saturation = Effects of atmos scattering are removed by finding the darkest pixels in an image and subtracting their values from all other pixels\nPseudo-invariant features = technique is based on the statistical invariance of the reflectance of man-made in-scene elements such as concrete, asphalt, and rooftops. Differences in the grey-level distributions of these invariant objects is assumed to be a linear function and is corrected statistically to perform the normalisation. The technique exhibits errors in reflectance of approximately 1% for Landsat TM and high-resolution air photo imagery in all spectral regions studied\n\n\nAbsolute = definitive\n\nChanging of digital brightness into scaled surface reflectance (amount of light reflected by the surface of the Earth)\nAbsolute correction is done via atmospheric radiative transfer models (many to select from)\nAbsolute data requirements\n\nModel - can be selected from the tool\nLocal atmospheric visibility - from places such as a weather station, etc\nImage altitude\n\nAbsolute tools (there are free and more expensive tools\n\nEmpirical line correction\n\nAlternative to radiative transfer modeling\nUses field spectrometer\n\nmeasures albedo (expression of the ability of surfaces to reflect heat from the sun)\n& spectral reflectance (fraction of incoming solar radiation that is reflected from Earth’s surface)\nHow it works = takes in light, break it into its spectral components, digitise the signal as a function of wavelength, and read it out and display it through a computer.\n\n\n\n\n\nOrthorectification/topographic\n\nDistortions are removed to allow for pixels to be viewed from straight above (at nadir)\n\nRequires sensor geometry and an elevation model (DEM = topographic representation of bare Earth surface excluding physical characteristics)\n\nFeatures within orthorectified image will be straightened (as influence of topography has been removed.\n\n\n\nFormulae that can be used for correction\n\nCosine correction = refers to the human perception of light incident on a surface. Light that lands on a matte surface is perceived based on the angle of incidence. Light coming from directly above is perceived more brightly than light that is perceived at low angles.\nC correction = advance of cosine correction\nMinnaert topographic correction = Used to interpret rough terrain by expressing radiance factor as function of phase angle\nStatistical empirical correction\n\nRadiometric calibration\n\nability to convert the digital numbers recorded by satellite imaging systems into physical units. Those units are either radiance (W/m2/sr/µm) or apparent top-of-atmosphere reflectance\nmeasurement of electromagnetic radiation and atomic particle radiation\nimportant to successfully convert raw digital image data from satellite or aerial sensors to a common physical scale based on known reflectance measurements taken from objects on the ground’s surface.  This type of correction is important for reliable quantitative measurements of the imagery.\ndifferences show up in the spectral signature associated with each pixel, and not difference in image.\n\n\nData joining \n\nWhat is it?\n\ntechnique that combines several images with overlapping parts (the images may be obtained at different times, different viewing angles or by different sensors) into a large-scale seamless high-resolution image\n\nWhy it’s necessary\n\nImage mosaicing is often a necessary process to cover a large and full region of interest (ROI) for many remote sensing applications (e.g., geographical mapping, resource and environmental monitoring, and disaster monitoring).\n\nHow it’s done\n\nOverlapping of different images\nFeathering =  soften the hard edges of an object in your image, i.e. blending of hard lines\nBase image will usually have one or more images layered on top\nImage enhancement\n\nConsiderations\n\nData joining allows image classification, i.e. the task of assigning classes—defined in a land cover and land use classification system, known as the schema—to all the pixels in a remotely sensed image. The output raster from image classification can be used to create thematic maps.\n\n\nImage enhancement\n\nWhat is it = the process of making an image more interpretable for a particular application (Faust, 1989). Enhancement makes important features of raw, remotely sensed data more interpretable to the human eye.\nMethod\n\nContrast enhancement\nSpatial filtering\nDensity slicing\n\nKey concepts\n\nSpectral (from EM spectrum) = the intensity of light as it varies with wavelength or frequency.\nIrradiance = Energy at all angles and directions.\nRadiance = energy reflected from source to sensor.\nReflectance = ratio of the amount of light leaving a target to the amount of light striking the target. It has no units. In other words, property of material/surface being observed.\nSurface reflectance = amount of light reflected by the surface of the Earth. It is a ratio of surface radiance to surface irradiance, and as such is unitless, with values between 0 and 1. In short, efficiency of surface in reflecting radiant energy.\nSpectral band = a region/range/layers in the EM spectrum in a range of wavelengths.\nSpectral signature = unique wavelength radiated by an object.\n\nApplications\n\nRaw remotely sensed image data are full of geometric and radiometric flaws caused by the curved shape of the Earth, the imperfectly transparent atmosphere, daily and seasonal variations in the amount of solar radiation received at the surface, and imperfections in scanning instruments, among other things.\nImage correction and enhancement methods allow for clearer image interpretation, resulting in more accurate interpretations of topography and physical features, which in turn allows for accurate analysis and on-the ground responses pertaining to land monitoring, disaster response, environmental study, and resource exploration.\n\nReflection\n\nAlthough most remotely sensed data nowadays has already been corrected and enhanced for ease of use, it is important to understand the methods and relevant situations.\nNo method is perfect, depends on situation and information available in order to conduct correction.\nAdditionally, not all remotely sensed data has been image corrected (depending on sensor source).\nUltimate goal is to eliminate any distortions to the best of our abilities to produce an image that best reflects the at-ground status of the location pictured by removing any possible factors of interference."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "2  Week 3: Image Correction and Data Joining",
    "section": "",
    "text": "MIT graduate, creator of Landsat and MultiSpectral System (MSS), pioneer of remote sensing.\n\nWhy image corrections are needed/ pre processing requirements\n\nNeeded when technical defects and deficiencies of the sensor and data transfer systems lead to mistakes in the image data construction.\nRaw remotely sensed image data are full of geometric and radiometric flaws caused by the curved shape of the Earth, the imperfectly transparent atmosphere, daily and seasonal variations in the amount of solar radiation received at the surface, and imperfections in scanning instruments, etc\n\n\n\nImagery correction types\n\nGeometric\n\nPurpose\n\nTo remove geometric distortion from a distorted image\nImage distortion can happen through rotation of Earth, wind from plane, uneven topography, off-nadir angle.\n\n\nSteps\n\nGround Control Points (GCP) for both image and map/reference coordinates are identified\nSensor model is built using GCP to give geometric transformation coefficients \n\nTransformation algorithms used to convert geometric (lat long) to geocentric (x,y) coordinates\n\nCoordinates are plotted to ensure line of best fit (minimal MSE) and variance for MSE (RMSE)\nResampling (used to calculate pixel values when one raster grid is fitted to another) to fix shift in data from sensor modeling\n\nTwo images (one correct/gold standard) overlap in order for pixels to line up\nAtmospheric\n\nPurpose\n\nTo remove scattering and absorption effects of the atmosphere on the reflectance values of images taken by satellite or airborne sensors\n2 main sources of environmental disturbance: atmos scattering & topographic attenuation (dimming and blurring effects)\n\nAtmos correction is only necessary for certain situations:\n\nSpectral signature (unique wavelength radiated by an object. Different objects have different signatures) through space and time\nBiophysical parameters (i.e. temperature, leaf area index, NDVI) are needed\nScattering leads to adjacency = radiance from nearby pixels is mixed into pixel of interest\nCorrection methods:\n\nRelative (when compared to others)\n\nSpectral band = A wavelength range in the spectrum of reflected or radiated electromagnetic (EM) energy to which a remote sensor is sensitive\nTo normalise intensities of different bands relative to each other within a single image\nTo normalise intensities of bands from many dates to one date\nRelative correction methods\n\nDark object saturation = Effects of atmos scattering are removed by finding the darkest pixels in an image and subtracting their values from all other pixels\nPseudo-invariant features = technique is based on the statistical invariance of the reflectance of man-made in-scene elements such as concrete, asphalt, and rooftops. Differences in the grey-level distributions of these invariant objects is assumed to be a linear function and is corrected statistically to perform the normalisation. The technique exhibits errors in reflectance of approximately 1% for Landsat TM and high-resolution air photo imagery in all spectral regions studied\n\n\nAbsolute = definitive\n\nChanging of digital brightness into scaled surface reflectance (amount of light reflected by the surface of the Earth)\nAbsolute correction is done via atmospheric radiative transfer models (many to select from)\nAbsolute data requirements\n\nModel - can be selected from the tool\nLocal atmospheric visibility - from places such as a weather station, etc\nImage altitude\n\nAbsolute tools (there are free and more expensive tools\n\nEmpirical line correction\n\nAlternative to radiative transfer modeling\nUses field spectrometer\n\nmeasures albedo (expression of the ability of surfaces to reflect heat from the sun)\n& spectral reflectance (fraction of incoming solar radiation that is reflected from Earth’s surface)\nHow it works = takes in light, break it into its spectral components, digitise the signal as a function of wavelength, and read it out and display it through a computer.\n\n\n\n\n\nOrthorectification/topographic\n\nDistortions are removed to allow for pixels to be viewed from straight above (at nadir)\n\nRequires sensor geometry and an elevation model (DEM = topographic representation of bare Earth surface excluding physical characteristics)\n\nFeatures within orthorectified image will be straightened (as influence of topography has been removed.\n\n\n\nFormulae that can be used for correction\n\nCosine correction = refers to the human perception of light incident on a surface. Light that lands on a matte surface is perceived based on the angle of incidence. Light coming from directly above is perceived more brightly than light that is perceived at low angles.\nC correction = advance of cosine correction\nMinnaert topographic correction = Used to interpret rough terrain by expressing radiance factor as function of phase angle\nStatistical empirical correction\n\nRadiometric calibration\n\nability to convert the digital numbers recorded by satellite imaging systems into physical units. Those units are either radiance (W/m2/sr/µm) or apparent top-of-atmosphere reflectance\nmeasurement of electromagnetic radiation and atomic particle radiation\nimportant to successfully convert raw digital image data from satellite or aerial sensors to a common physical scale based on known reflectance measurements taken from objects on the ground’s surface.  This type of correction is important for reliable quantitative measurements of the imagery.\ndifferences show up in the spectral signature associated with each pixel, and not difference in image.\n\n\nData joining \n\nWhat is it?\n\ntechnique that combines several images with overlapping parts (the images may be obtained at different times, different viewing angles or by different sensors) into a large-scale seamless high-resolution image\n\nWhy it’s necessary\n\nImage mosaicing is often a necessary process to cover a large and full region of interest (ROI) for many remote sensing applications (e.g., geographical mapping, resource and environmental monitoring, and disaster monitoring).\n\nHow it’s done\n\nOverlapping of different images\nFeathering =  soften the hard edges of an object in your image, i.e. blending of hard lines\nBase image will usually have one or more images layered on top\nImage enhancement\n\nConsiderations\n\nData joining allows image classification, i.e. the task of assigning classes—defined in a land cover and land use classification system, known as the schema—to all the pixels in a remotely sensed image. The output raster from image classification can be used to create thematic maps.\n\n\nImage enhancement\n\nWhat is it = the process of making an image more interpretable for a particular application (Faust, 1989). Enhancement makes important features of raw, remotely sensed data more interpretable to the human eye.\nMethod\n\nContrast enhancement\nSpatial filtering\nDensity slicing\n\n\nKey concepts\n\nSpectral (from EM spectrum) = the intensity of light as it varies with wavelength or frequency.\nIrradiance = Energy at all angles and directions.\nRadiance = energy reflected from source to sensor.\nReflectance = ratio of the amount of light leaving a target to the amount of light striking the target. It has no units. In other words, property of material/surface being observed.\nSurface reflectance = amount of light reflected by the surface of the Earth. It is a ratio of surface radiance to surface irradiance, and as such is unitless, with values between 0 and 1. In short, efficiency of surface in reflecting radiant energy.\nSpectral band = a region/range/layers in the EM spectrum in a range of wavelengths.\nSpectral signature = unique wavelength radiated by an object.\n\nApplications\n\nRaw remotely sensed image data are full of geometric and radiometric flaws caused by the curved shape of the Earth, the imperfectly transparent atmosphere, daily and seasonal variations in the amount of solar radiation received at the surface, and imperfections in scanning instruments, among other things.\nImage correction and enhancement methods allow for clearer image interpretation, resulting in more accurate interpretations of topography and physical features, which in turn allows for accurate analysis and on-the ground responses pertaining to land monitoring, disaster response, environmental study, and resource exploration.\n\nReflection\n\nAlthough most remotely sensed data nowadays has already been corrected and enhanced for ease of use, it is important to understand the methods and relevant situations.\nNo method is perfect, depends on situation and information available in order to conduct correction.\nAdditionally, not all remotely sensed data has been image corrected (depending on sensor source).\nUltimate goal is to eliminate any distortions to the best of our abilities to produce an image that best reflects the at-ground status of the location pictured by removing any possible factors of interference."
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "3  Week 4: Policy Applications",
    "section": "",
    "text": "Malaysia’s disaster risk profile\n\nWorst floods in the past 30 years have occurred from 2003 onwards. The majority of natural disasters from 1998 to 2018 were natural disasters (38/51).\nMalaysia had the highest percentage (67%) of the population exposed to floods among ASEAN Member States (between July 2012 and January 2019) as reported by ASEAN Coordinating Centre for Humanitarian Assistance on disaster management in March 2019.\nNine percent of land area in Malaysia is flood prone and 4.8 million people live in areas at risk to flood.\nMonsoon and flash floods are the primary climate related natural disasters in the country.\nMalaysia’s flood prone area covers approximately 29 km and affects more than 4.82 million people. \nAdditionally, annual damage caused by floods has cost an annual US $4.82 million.\nMost areas of the Asian region lack sufficient observational records to draw conclusions about trends in annual precipitation over the past century (seeWGIAR5 Chapter 2; Figure 24-2;Table SM24-2).\n\n\nCornerstone of Malaysian framework creation\n\nLocal directives and plans\n\nBased on Directive 20 of National Disaster Management Relief (acts as a framework for policy building), Directive 20 is carried out by the National Disaster Management and Relief Committee (NDRMC)\nEleventh Malaysia Plan: Chapter 6, Focus Area D: Strengthening Resilience Against Climate Change and Natural Disasters. As Malaysia develops socioeconomically, the country is focused on resilient growth to ensure its development gains are not reversed by natural disasters. Therefore, planning and preparing for natural disasters, identifying which areas and communities are at risk, and providing the right tools in case such situations occur are important strategies highlighted in the Plan with regard to preparing a comprehensive disaster risk management (DM) framework and protecting the resiliency of the country and its future.\n\nInternationally ratified agreements and frameworks\n\nCOP26\nC40 Cities\nSustainable Developments Goals\nSendai framework\n\nLaws and policies\n\nPreventative measures instituted to minimise impact \n\nThe Land Conservation Act 1960 \nEnvironmental Quality Act 1974 \nLocal Government Act 1976 \nRoad, Drainage and Building Act 1974\nOccupational Safety and Health Act 1994\nUniform Building Bylaws 1984 \n\nDisaster Risk Management Laws include\n\n1951 Civil Defence Act (Revised 1979) \n1964 Emergency (Essential Powers) Act \n1979 Emergency (Essential Powers) Act \n1997 Policy and Mechanism of National \nDisaster Management and Relief NSC Directive \n1998 Prevention and Control of Infectious Diseases Act \n1998 Fire Services Act 341 \n2016 Civil Defence (Amendment)\n2016 National Security Council Act\nAdditional Acts\n\nNational Security Act 2016\n\n\n\n\nMalaysian Disaster Risk Reduction and Mitigation Framework\n\nNational Disaster Management and Relief Committee (NDRMC):\n\nIn charge of crafting national policies pertaining to disaster response using the No.20 directive as a guideline.\n\nNational Disaster Management Agency (NADMA)\n\nNADMA is focal point of disaster risk reduction\nNADMA consolidates roles of different agencies, such as\n\nDisaster management division of NSC\nPost flood recovery unity of PM dept\nSpecial Malaysia Disaster Assistance and Rescue Agency (SMART)\nUnder NADMA, strategic partners include\n\n NADMA is also responsible for Early Communications System, which consists of:\n\nMMD (Malaysian Meteorological Department)\nDepartment of Irrigation and Drainage\nMalaysian Remote Sensing Agency\n\n\n\nHow can remotely sensed data be applied to solve policy challenges?\n\nCurrent policy challenge\n\npolicies which exist are not comprehensive enough to plan ahead of disaster risk, and are too reactive in nature. Additionally, not all relevant departments are tied to disaster-related policies (Ministry of Works, Ministry of Housing, Ministry of Agriculture, etc).\n\nPolicy goals\n\n A more comprehensive response to account for all stages of disaster preparedness and mitigation. This will help in preempting locations within Malaysia which may suffer from a risk of disasters in the future, allowing for the implementation of planning laws that can help address this issue before population displacement happens. \nMore holistic policies will also help to align the country’s goals  with internationally ratified agreements, many of which Malaysia is a part of. These include COP26, C40 cities, Sendai Framework, Sustainable Development Goals under the UNDP, and more. \nTo expand accessibility of findings beyond disaster response to incorporate involvement of all relevant departments and ministries.\n\nHow to address this using remotely sensed data\n\nSAR-based flood monitoring for accurate real-time monitoring\n\nRapid assessment: Quick acquisition and processing of data, enabling faster response to flood events\nWide-area coverage: Large-scale flood monitoring, even in remote or inaccessible areas\nAll-weather capability: Reliable data collection, regardless of weather conditions or time of day\n\nModel for future flood-prone area prediction\n\n\nReflection on lessons learned (in relation to policy, city and the application of the data)\n\nPolicy implementation requires proper coordination between relevant stakeholders to carry out policy goals in an efficient manner, with each key player understanding which part they play. Fragmentation and unclear division of labour in terms of role responsibility may cause confusion due to overlapping roles.\nThe democratisation of data accessibility and the development of satellite data has allowed for more creative methods of solving issues pertaining to natural disasters. This is especially important for developing countries, particularly in the global South with lack of access to technology and manpower to help assess issues and form relevant solutions.\nDespite the existence of internationally ratified agreements working towards forming sustainable city policies, many developing nations are at a significant disadvantage due to a lack of prior access and technology. While richer nations (typically located in the West) may already have infrastructure in place, poorer nations are still working towards building infrastructure. As a result, their preparedness and response times to disasters are delayed."
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "4  Week 5: Data Classification",
    "section": "",
    "text": "The process of separating and organising data into relevant groups (“classes”) based on their shared characteristics. Within remotely sensed data, these traits can be in the form of topography, temperature, etc.\n\n\nHow is classified data used in a practical setting?\n\nObservation of urban expansion using Landsat data\nObservation of Land Use and Land Cover (LULC) and its effects on air pollution, using Sentinel-3 (Sea and Land Surface Temperature) and Sentinel-5 (Precursor Major Air Pollutants)\nDetection of urban green spaces\nMonitoring of forest density/illegal logging practices\nMapping of forest fire spread for hazard determination\n\nClassification methods\n\nMachine learning method types/ types of decision tree algorithms\nDecision and Classification trees (CART)\n\nCART is a decision tree algorithm useful for both classification and regression tasks.The algorithm starts with the whole dataset and selects the variable that best splits the data into two groups based on a certain standard/criterion, such as the Gini index. The algorithm then creates a node at the top of the tree that corresponds to this split, and the data is divided into two subsets based on the values of the selected variable. The same process is repeated for each subset, and the tree is grown until a stopping criterion is met. It is prone to overfitting, where the model becomes too complex and fits the noise in the data rather than the underlying pattern. To overcome this, techniques such as pruning, regularisation, and ensemble methods can be used to improve the performance and generalisation of the model.\nBenefits of CART include ease of interpretability of findings, the ability to handle mixed datasets, it does not make assumptions about the underlying distribution of the data (non-parametric), and it is scalable depending on the size and dimensionality of the dataset. On the other hand, limitations include instability of the model due to the likelihood of a different tree being generated due to a slight change in data, and overfitting. \nA study conducted using CART titled “Using classification and regression tree modelling to investigate response shift patterns in dentine hypersensitivity” utilises regression trees to determine patterns of people’s response shift to dentine hypersensitivity, with the intention to explore the convergent validity with other design-based approaches.\n\nRegression trees\n\nRegression trees are a decision tree algorithm used for predicting continuous numerical values. Regression trees work by recursively partitioning the feature space into non-overlapping regions or segments, where each segment corresponds to a specific prediction value for the target variable. At each node of the tree, the algorithm selects the feature and threshold that provides the best split of the data, based on a metric such as mean squared error (MSE) or mean absolute error (MAE). The data are then split into two subsets based on the selected feature and threshold. Process is repeated until the criterion is met.\nBenefits of regression trees include the ability to capture non-linear interactions between input variables, robustness of functionality despite missing data, and capability for outlier detection. However limitations include limited extrapolation ability (resulting in unreliable predictions when input variables are outside of data range), and poor performance when working on imbalanced datasets (such as small sample sizes and imbalanced class distributions). \nA study using regression trees titled “Use of Regression Tree Analysis for Predicting the Functional Outcome after Traumatic Spinal Cord Injury” utilises regression trees as a method to predict long-term functional outcomes of patients suffering from traumatic spinal cord injury (TSCI) in order to adapt medical strategies and plan an optimised rehabilitation.\n\n\nReferences"
  }
]